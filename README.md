## MoodBeatz: Leveraging Facial Expression Analysis for Personalized Music Experience  

MoodBeatz is an AI-powered music recommendation system that analyzes facial expressions to suggest songs based on the user’s emotions. It utilizes **Mediapipe** for face detection, **OpenCV** for preprocessing, and **TensorFlow/Keras** with a **CNN model** for emotion classification. The system detects emotions like Happy, Sad, Angry, and Neutral, recommending music through the **Spotify or YouTube API**. By integrating **machine learning, computer vision, and music streaming**, MoodBeatz aims to enhance the user’s listening experience with personalized song selections.

## About
MoodBeatz is an AI-driven music recommendation system that personalizes song suggestions based on a user’s facial expressions. It leverages advanced machine learning and computer vision techniques to analyze real-time emotions and map them to an appropriate music playlist. By integrating Mediapipe for face detection, OpenCV for image preprocessing, and TensorFlow/Keras for emotion classification, MoodBeatz creates an immersive and dynamic listening experience.
## Features
Real-time Facial Expression Analysis – Detects user emotions through live webcam input.
AI-Powered Emotion Classification – Uses a CNN model trained with TensorFlow/Keras for accurate emotion detection.
Seamless Music Recommendation – Integrates Spotify API or YouTube API to suggest songs based on detected emotions.
Advanced Image Processing – Utilizes Mediapipe for facial landmark detection and OpenCV for preprocessing.
User-Friendly Interface – Simple and interactive design for smooth user experience.

## Requirements

- Intel i5 or higher / AMD Ryzen 5 or higher processor  
- Minimum 8GB RAM (16GB recommended)  
- At least 10GB free storage space  
- Webcam for real-time facial detection  
- NVIDIA GPU (recommended for faster CNN execution)  
- Windows 10/11, macOS, or Linux operating system  
- Python 3.8+ programming language  
- TensorFlow/Keras for deep learning model training  
- Mediapipe for real-time face detection  
- OpenCV for image preprocessing  
- NumPy & Pandas for data handling  
- Spotify API / YouTube API for music recommendations  
- Visual Studio Code / Jupyter Notebook / PyCharm as IDE  
- Stable internet connection for API integration and cloud-based model processing  

## System Architecture

![image](https://github.com/user-attachments/assets/3e88500c-8778-41b4-95f5-5023a050289c)


## Output

![image](https://github.com/user-attachments/assets/51eb35bf-d759-461b-b731-7de353c59443)



## Results and Impact
Successfully detects and classifies facial expressions in real-time using a CNN model.
Provides accurate and personalized music recommendations based on user emotions.
Enhances user experience by automating song selection through AI-driven emotion recognition.
Helps in mood regulation and emotional well-being by playing music that aligns with the user's feelings.
Can be integrated into entertainment, mental health, and smart home applications for broader usability.
## Articles published / References
1.Mollahosseini, A., Hasani, B., & Mahoor, M. H. (2016). Facial Emotion Recognition using Deep Learning. Proceedings of the 2016 IEEE Winter Conference on Applications of Computer Vision.
DOI: 10.1109/WACV.2016.7477525

2.Basu, C., & Jannach, D. (2011). A Survey on Music Recommendation Systems. Computer Science Review, 5(1), 3-10.
DOI: 10.1016/j.cosrev.2011.01.001

3.Zhang, Z., & Lu, B. (2019). Emotion Recognition using Multimodal Sensor Data. IEEE Transactions on Affective Computing, 10(4), 389-399.
DOI: 10.1109/TAFFC.2019.2905364

4.Picard, R. W. (1997). Affective Computing. MIT Press.
ISBN: 978-0262661147

5.Ekman, P., & Friesen, W. V. (1978). Facial Action Coding System: A Technique for the Measurement of Facial Movement. Consulting Psychologists Press.
ISBN: 978-0918282151




